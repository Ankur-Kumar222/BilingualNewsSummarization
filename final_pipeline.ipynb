{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "import pandas as pd\n",
    "import numpy as np1\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key=\"8c82dafbeadf4751b73b573fb7b6671e\")\n",
    "data = newsapi.get_sources()\n",
    "\n",
    "# Classify sources by category\n",
    "categories = {}\n",
    "countries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in data['sources']:\n",
    "    category = source['category']\n",
    "    country = source['country']\n",
    "    \n",
    "    if category not in categories:\n",
    "        categories[category] = []\n",
    "    categories[category].append(source)\n",
    "    \n",
    "    if country not in countries:\n",
    "        countries[country] = []\n",
    "    countries[country].append(source)\n",
    "\n",
    "def create_dataframe(data_dict, outer_key_name, inner_key_name):\n",
    "    records = []\n",
    "    for outer_key, sources in data_dict.items():\n",
    "        for source in sources:\n",
    "            record = {\n",
    "                outer_key_name: outer_key,\n",
    "                inner_key_name: source['name'],\n",
    "                'id': source['id'],\n",
    "                'description': source['description'],\n",
    "                'url': source['url'],\n",
    "                'category': source['category'],\n",
    "                'language': source['language'],\n",
    "                'country': source['country']\n",
    "            }\n",
    "            records.append(record)\n",
    "    return pd.DataFrame(records).set_index([outer_key_name, inner_key_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for categories\n",
    "df_categories = create_dataframe(categories, 'Category', 'Source Name')\n",
    "yesterday_date = (datetime.now() - timedelta(days=10)).strftime('%Y-%m-%d')\n",
    "df_categories['yesterday_date'] = yesterday_date\n",
    "df_categories.drop(labels='category', axis=1, inplace=True)\n",
    "\n",
    "# Create DataFrame for countries\n",
    "df_countries = create_dataframe(countries, 'Country', 'Source Name')\n",
    "\n",
    "list_sources = ['abc-news', 'al-jazeera-english', 'bbc-news', 'google-news', 'google-news-in', 'politico', 'reuters', 'reddit-r-all', 'the-hindu', 'bloomberg', \n",
    "                'the-times-of-india', 'business-insider', 'vice-news', 'the-wall-street-journal', 'wired', 'national-geographic', 'bbc-sport', 'espn', 'techcrunch',\n",
    "                'crypto-coins-news','buzzfeed','entertainment-weekly','medical-news-today','fortune','new-scientist','the-lad-bible', 'new-york-magazine', 'the-washington-times',\n",
    "                'the-washington-post', 'cnn', 'ign', 'the-verge', 'fox-sports', 'talksport', 'the-sport-bible', 'hacker-news', 'recode', 'the-next-web', 'entertainment-weekly',\n",
    "                'time', 'the-hindu', 'cbs-news', 'asutralian-financial-review', 'business-insider-uk', 'financial-post', 'fortune', 'info-money']\n",
    "\n",
    "df_categories = df_categories[df_categories['id'].isin(list_sources)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "print(len(list_sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_json(source_id, date):\n",
    "    url = (f'https://newsapi.org/v2/everything?'\n",
    "           f'sources={source_id}&'\n",
    "           f'from={date}&'\n",
    "           'sortBy=popularity&'\n",
    "           'apiKey=8c82dafbeadf4751b73b573fb7b6671e')\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    return response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_content(urls):\n",
    "#     contents = []\n",
    "#     for url in urls:\n",
    "#         try:\n",
    "#             response = requests.get(url)\n",
    "#             soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#             article_content = soup.find_all('p')\n",
    "#             content_text = ' '.join([paragraph.get_text() for paragraph in article_content])\n",
    "#             contents.append(content_text)\n",
    "#         except Exception as e:\n",
    "#             contents.append(f\"Error: {str(e)}\")\n",
    "#     return contents\n",
    "\n",
    "def scrape_content(urls):\n",
    "    contents = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()  # Raise an error for bad status codes\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Attempt to find the main content using common HTML structures\n",
    "            article_content = soup.find('article')\n",
    "            if not article_content:\n",
    "                # Fallback to more general selectors if <article> is not found\n",
    "                article_content = soup.find('div', class_='main-content')\n",
    "            if not article_content:\n",
    "                # Fallback to another common class name\n",
    "                article_content = soup.find('div', class_='article-body')\n",
    "            if not article_content:\n",
    "                # As a last resort, get all paragraphs but this might include ads\n",
    "                article_content = soup.find_all('p')\n",
    "                content_text = ' '.join([paragraph.get_text() for paragraph in article_content])\n",
    "            else:\n",
    "                # Extract all paragraphs within the main content\n",
    "                paragraphs = article_content.find_all('p')\n",
    "                content_text = ' '.join([paragraph.get_text() for paragraph in paragraphs])\n",
    "\n",
    "            contents.append(content_text)\n",
    "        except Exception as e:\n",
    "            contents.append(f\"Error: {str(e)}\")\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df(data):\n",
    "    try:\n",
    "        articles = data['articles']\n",
    "        if not articles:\n",
    "            raise ValueError(\"No articles found for the given date.\")\n",
    "        \n",
    "        df = pd.DataFrame(articles)\n",
    "        df = df[['author', 'title', 'url', 'description', 'publishedAt']]\n",
    "        df.columns = ['author', 'title', 'url', 'description', 'date']\n",
    "        \n",
    "        # Adding the content column by scraping the URLs\n",
    "        df['content'] = scrape_content(df['url'])\n",
    "        \n",
    "        return df\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove rows with empty content\n",
    "def remove_empty_content(df):\n",
    "    if 'content' in df.columns:\n",
    "        # Removing rows with empty content\n",
    "        df = df[df['content'].str.strip().astype(bool)]\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>yesterday_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Source Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <th>Al Jazeera English</th>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>News, analysis from the Middle East and worldw...</td>\n",
       "      <td>https://www.aljazeera.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "Category Source Name                              \n",
       "general  Al Jazeera English  al-jazeera-english   \n",
       "\n",
       "                                                                   description  \\\n",
       "Category Source Name                                                             \n",
       "general  Al Jazeera English  News, analysis from the Middle East and worldw...   \n",
       "\n",
       "                                                   url language country  \\\n",
       "Category Source Name                                                      \n",
       "general  Al Jazeera English  https://www.aljazeera.com       en      us   \n",
       "\n",
       "                            yesterday_date  \n",
       "Category Source Name                        \n",
       "general  Al Jazeera English     2024-06-07  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 1\n",
    "df_trial = df_categories.iloc[[n], :].copy()\n",
    "df_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trial = df_categories.iloc[[n], :].copy()\n",
    "df_trial['data'] = df_trial.apply(\n",
    "    lambda row: json_to_df(fetch_json(row['id'], row['yesterday_date'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Apply the function to clean up each DataFrame in the 'data' column\n",
    "df_trial['data'] = df_trial['data'].apply(remove_empty_content)\n",
    "# Remove rows where 'data' column has empty DataFrames\n",
    "df_trial1 = df_trial[df_trial['data'].apply(lambda x: not x.empty)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>yesterday_date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Source Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <th>Al Jazeera English</th>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>News, analysis from the Middle East and worldw...</td>\n",
       "      <td>https://www.aljazeera.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>author                         ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "Category Source Name                              \n",
       "general  Al Jazeera English  al-jazeera-english   \n",
       "\n",
       "                                                                   description  \\\n",
       "Category Source Name                                                             \n",
       "general  Al Jazeera English  News, analysis from the Middle East and worldw...   \n",
       "\n",
       "                                                   url language country  \\\n",
       "Category Source Name                                                      \n",
       "general  Al Jazeera English  https://www.aljazeera.com       en      us   \n",
       "\n",
       "                            yesterday_date  \\\n",
       "Category Source Name                         \n",
       "general  Al Jazeera English     2024-06-07   \n",
       "\n",
       "                                                                          data  \n",
       "Category Source Name                                                            \n",
       "general  Al Jazeera English                 author                         ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\3842372735.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>description</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Hospital overwhelmed with victims of Israeli a...</td>\n",
       "      <td>https://www.aljazeera.com/gallery/2024/6/8/hos...</td>\n",
       "      <td>At least 210 dead and more wounded in Israeli ...</td>\n",
       "      <td>2024-06-08T16:00:20Z</td>\n",
       "      <td>In Pictures Gaza’s Government Media Office say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gerald Nesmith Jr</td>\n",
       "      <td>The fallacy of the ‘wrong side of history’ nar...</td>\n",
       "      <td>https://www.aljazeera.com/opinions/2024/6/9/th...</td>\n",
       "      <td>Waiting on history to deliver karmic justice i...</td>\n",
       "      <td>2024-06-09T13:11:32Z</td>\n",
       "      <td>Waiting on history to deliver karmic justice f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Russia-Ukraine war: List of key events, day 836</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/10/russi...</td>\n",
       "      <td>These are the main developments as the war ent...</td>\n",
       "      <td>2024-06-10T11:36:25Z</td>\n",
       "      <td>As the war enters its 836th day, these are the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Mexico heatwave killing monkeys, lions offered...</td>\n",
       "      <td>https://www.aljazeera.com/gallery/2024/6/11/me...</td>\n",
       "      <td>Dozens of howler monkeys were found dead in th...</td>\n",
       "      <td>2024-06-11T09:08:29Z</td>\n",
       "      <td>In Pictures Amid Mexico’s heatwave and drought...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Clashes erupt between police and protesters as...</td>\n",
       "      <td>https://www.aljazeera.com/gallery/2024/6/13/cl...</td>\n",
       "      <td>President Javier Milei seeks to pass a key bil...</td>\n",
       "      <td>2024-06-13T01:39:16Z</td>\n",
       "      <td>In Pictures Violent protests have erupted on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>More than 80 dead in DR Congo after boat capsizes</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/12/dozen...</td>\n",
       "      <td>This is a breaking news story, more details to...</td>\n",
       "      <td>2024-06-12T14:54:58Z</td>\n",
       "      <td>President Felix Tshisekedi calls for investiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Russia-Ukraine war: List of key events, day 837</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/11/russi...</td>\n",
       "      <td>As the war enters is 837th day, these are the ...</td>\n",
       "      <td>2024-06-11T01:52:51Z</td>\n",
       "      <td>As the war enters is 837th day, these are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Russia-Ukraine war: List of key events, day 838</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/12/russi...</td>\n",
       "      <td>As the war enters its 838th day, these are the...</td>\n",
       "      <td>2024-06-12T01:15:40Z</td>\n",
       "      <td>As the war enters its 838th day, these are the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>At least 35 dead in Kuwait building fire</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/12/dozen...</td>\n",
       "      <td>Fire erupts in building in southern Mangaf dis...</td>\n",
       "      <td>2024-06-12T09:26:22Z</td>\n",
       "      <td>Fire erupts in building in southern Mangaf dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Photos: Nomadic Muslims throng forest shrine i...</td>\n",
       "      <td>https://www.aljazeera.com/gallery/2024/6/13/ph...</td>\n",
       "      <td>The 19th-century shrine to Mian Nizamuddin Kiy...</td>\n",
       "      <td>2024-06-13T11:10:12Z</td>\n",
       "      <td>In Pictures The road to the Baba Nagri forest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>Russia-Ukraine war: List of key events, day 840</td>\n",
       "      <td>https://www.aljazeera.com/news/2024/6/14/russi...</td>\n",
       "      <td>As the war enters its 840th day, these are the...</td>\n",
       "      <td>2024-06-14T00:48:50Z</td>\n",
       "      <td>As the war enters its 840th day, these are the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                              title  \\\n",
       "0          Al Jazeera  Hospital overwhelmed with victims of Israeli a...   \n",
       "1   Gerald Nesmith Jr  The fallacy of the ‘wrong side of history’ nar...   \n",
       "2          Al Jazeera    Russia-Ukraine war: List of key events, day 836   \n",
       "3          Al Jazeera  Mexico heatwave killing monkeys, lions offered...   \n",
       "4          Al Jazeera  Clashes erupt between police and protesters as...   \n",
       "5          Al Jazeera  More than 80 dead in DR Congo after boat capsizes   \n",
       "6          Al Jazeera    Russia-Ukraine war: List of key events, day 837   \n",
       "7          Al Jazeera    Russia-Ukraine war: List of key events, day 838   \n",
       "8          Al Jazeera           At least 35 dead in Kuwait building fire   \n",
       "9          Al Jazeera  Photos: Nomadic Muslims throng forest shrine i...   \n",
       "10         Al Jazeera    Russia-Ukraine war: List of key events, day 840   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.aljazeera.com/gallery/2024/6/8/hos...   \n",
       "1   https://www.aljazeera.com/opinions/2024/6/9/th...   \n",
       "2   https://www.aljazeera.com/news/2024/6/10/russi...   \n",
       "3   https://www.aljazeera.com/gallery/2024/6/11/me...   \n",
       "4   https://www.aljazeera.com/gallery/2024/6/13/cl...   \n",
       "5   https://www.aljazeera.com/news/2024/6/12/dozen...   \n",
       "6   https://www.aljazeera.com/news/2024/6/11/russi...   \n",
       "7   https://www.aljazeera.com/news/2024/6/12/russi...   \n",
       "8   https://www.aljazeera.com/news/2024/6/12/dozen...   \n",
       "9   https://www.aljazeera.com/gallery/2024/6/13/ph...   \n",
       "10  https://www.aljazeera.com/news/2024/6/14/russi...   \n",
       "\n",
       "                                          description                  date  \\\n",
       "0   At least 210 dead and more wounded in Israeli ...  2024-06-08T16:00:20Z   \n",
       "1   Waiting on history to deliver karmic justice i...  2024-06-09T13:11:32Z   \n",
       "2   These are the main developments as the war ent...  2024-06-10T11:36:25Z   \n",
       "3   Dozens of howler monkeys were found dead in th...  2024-06-11T09:08:29Z   \n",
       "4   President Javier Milei seeks to pass a key bil...  2024-06-13T01:39:16Z   \n",
       "5   This is a breaking news story, more details to...  2024-06-12T14:54:58Z   \n",
       "6   As the war enters is 837th day, these are the ...  2024-06-11T01:52:51Z   \n",
       "7   As the war enters its 838th day, these are the...  2024-06-12T01:15:40Z   \n",
       "8   Fire erupts in building in southern Mangaf dis...  2024-06-12T09:26:22Z   \n",
       "9   The 19th-century shrine to Mian Nizamuddin Kiy...  2024-06-13T11:10:12Z   \n",
       "10  As the war enters its 840th day, these are the...  2024-06-14T00:48:50Z   \n",
       "\n",
       "                                              content  \n",
       "0   In Pictures Gaza’s Government Media Office say...  \n",
       "1   Waiting on history to deliver karmic justice f...  \n",
       "2   As the war enters its 836th day, these are the...  \n",
       "3   In Pictures Amid Mexico’s heatwave and drought...  \n",
       "4   In Pictures Violent protests have erupted on t...  \n",
       "5   President Felix Tshisekedi calls for investiga...  \n",
       "6   As the war enters is 837th day, these are the ...  \n",
       "7   As the war enters its 838th day, these are the...  \n",
       "8   Fire erupts in building in southern Mangaf dis...  \n",
       "9   In Pictures The road to the Baba Nagri forest ...  \n",
       "10  As the war enters its 840th day, these are the...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial1['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\3725325152.py:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = df_trial1['data'][0]['content'][5]\n"
     ]
    }
   ],
   "source": [
    "text = df_trial1['data'][0]['content'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text has been saved to output.txt\n"
     ]
    }
   ],
   "source": [
    "# Replace each period with a period followed by a newline character\n",
    "formatted_text = text.replace('.', '.\\n')\n",
    "\n",
    "# Define the filename\n",
    "filename = 'output.txt'\n",
    "\n",
    "# Open the file in write mode and save the formatted text\n",
    "with open(filename, 'w',encoding='utf-8') as file:\n",
    "    file.write(formatted_text)\n",
    "\n",
    "print(f\"The text has been saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>yesterday_date</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Source Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <th>Al Jazeera English</th>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>News, analysis from the Middle East and worldw...</td>\n",
       "      <td>https://www.aljazeera.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "      <td>author                         ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id  \\\n",
       "Category Source Name                              \n",
       "general  Al Jazeera English  al-jazeera-english   \n",
       "\n",
       "                                                                   description  \\\n",
       "Category Source Name                                                             \n",
       "general  Al Jazeera English  News, analysis from the Middle East and worldw...   \n",
       "\n",
       "                                                   url language country  \\\n",
       "Category Source Name                                                      \n",
       "general  Al Jazeera English  https://www.aljazeera.com       en      us   \n",
       "\n",
       "                            yesterday_date  \\\n",
       "Category Source Name                         \n",
       "general  Al Jazeera English     2024-06-07   \n",
       "\n",
       "                                                                          data  \n",
       "Category Source Name                                                            \n",
       "general  Al Jazeera English                 author                         ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>country</th>\n",
       "      <th>yesterday_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th>Source Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">general</th>\n",
       "      <th>ABC News</th>\n",
       "      <td>abc-news</td>\n",
       "      <td>Your trusted source for breaking news, analysi...</td>\n",
       "      <td>https://abcnews.go.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Al Jazeera English</th>\n",
       "      <td>al-jazeera-english</td>\n",
       "      <td>News, analysis from the Middle East and worldw...</td>\n",
       "      <td>https://www.aljazeera.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BBC News</th>\n",
       "      <td>bbc-news</td>\n",
       "      <td>Use BBC News for up-to-the-minute news, breaki...</td>\n",
       "      <td>https://www.bbc.co.uk/news</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CBS News</th>\n",
       "      <td>cbs-news</td>\n",
       "      <td>CBS News: dedicated to providing the best in j...</td>\n",
       "      <td>http://www.cbsnews.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CNN</th>\n",
       "      <td>cnn</td>\n",
       "      <td>View the latest news and breaking news today f...</td>\n",
       "      <td>http://us.cnn.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google News</th>\n",
       "      <td>google-news</td>\n",
       "      <td>Comprehensive, up-to-date news coverage, aggre...</td>\n",
       "      <td>https://news.google.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Google News (India)</th>\n",
       "      <td>google-news-in</td>\n",
       "      <td>Comprehensive, up-to-date India news coverage,...</td>\n",
       "      <td>https://news.google.com</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York Magazine</th>\n",
       "      <td>new-york-magazine</td>\n",
       "      <td>NYMAG and New York magazine cover the new, the...</td>\n",
       "      <td>http://nymag.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politico</th>\n",
       "      <td>politico</td>\n",
       "      <td>Political news about Congress, the White House...</td>\n",
       "      <td>https://www.politico.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reddit /r/all</th>\n",
       "      <td>reddit-r-all</td>\n",
       "      <td>Reddit is an entertainment, social news networ...</td>\n",
       "      <td>https://www.reddit.com/r/all</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reuters</th>\n",
       "      <td>reuters</td>\n",
       "      <td>Reuters.com brings you the latest news from ar...</td>\n",
       "      <td>https://www.reuters.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Hindu</th>\n",
       "      <td>the-hindu</td>\n",
       "      <td>The Hindu. latest news, analysis, comment, in-...</td>\n",
       "      <td>http://www.thehindu.com</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Times of India</th>\n",
       "      <td>the-times-of-india</td>\n",
       "      <td>Times of India brings the Latest News and Top ...</td>\n",
       "      <td>http://timesofindia.indiatimes.com</td>\n",
       "      <td>en</td>\n",
       "      <td>in</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Washington Post</th>\n",
       "      <td>the-washington-post</td>\n",
       "      <td>Breaking news and analysis on politics, busine...</td>\n",
       "      <td>https://www.washingtonpost.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Washington Times</th>\n",
       "      <td>the-washington-times</td>\n",
       "      <td>The Washington Times delivers breaking news an...</td>\n",
       "      <td>https://www.washingtontimes.com/</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>time</td>\n",
       "      <td>Breaking news and analysis from TIME.com. Poli...</td>\n",
       "      <td>http://time.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vice News</th>\n",
       "      <td>vice-news</td>\n",
       "      <td>Vice News is Vice Media, Inc.'s current affair...</td>\n",
       "      <td>https://news.vice.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">business</th>\n",
       "      <th>Bloomberg</th>\n",
       "      <td>bloomberg</td>\n",
       "      <td>Bloomberg delivers business and markets news, ...</td>\n",
       "      <td>http://www.bloomberg.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider</th>\n",
       "      <td>business-insider</td>\n",
       "      <td>Business Insider is a fast-growing business si...</td>\n",
       "      <td>http://www.businessinsider.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Business Insider (UK)</th>\n",
       "      <td>business-insider-uk</td>\n",
       "      <td>Business Insider is a fast-growing business si...</td>\n",
       "      <td>http://uk.businessinsider.com</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financial Post</th>\n",
       "      <td>financial-post</td>\n",
       "      <td>Find the latest happenings in the Canadian Fin...</td>\n",
       "      <td>https://financialpost.com</td>\n",
       "      <td>en</td>\n",
       "      <td>ca</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fortune</th>\n",
       "      <td>fortune</td>\n",
       "      <td>Fortune 500 Daily and Breaking Business News</td>\n",
       "      <td>http://fortune.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InfoMoney</th>\n",
       "      <td>info-money</td>\n",
       "      <td>No InfoMoney você encontra tudo o que precisa ...</td>\n",
       "      <td>https://www.infomoney.com.br</td>\n",
       "      <td>pt</td>\n",
       "      <td>br</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Wall Street Journal</th>\n",
       "      <td>the-wall-street-journal</td>\n",
       "      <td>WSJ online coverage of breaking news and curre...</td>\n",
       "      <td>http://www.wsj.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">technology</th>\n",
       "      <th>Crypto Coins News</th>\n",
       "      <td>crypto-coins-news</td>\n",
       "      <td>Providing breaking cryptocurrency news - focus...</td>\n",
       "      <td>https://www.ccn.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hacker News</th>\n",
       "      <td>hacker-news</td>\n",
       "      <td>Hacker News is a social news website focusing ...</td>\n",
       "      <td>https://news.ycombinator.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recode</th>\n",
       "      <td>recode</td>\n",
       "      <td>Get the latest independent tech news, reviews ...</td>\n",
       "      <td>http://www.recode.net</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TechCrunch</th>\n",
       "      <td>techcrunch</td>\n",
       "      <td>TechCrunch is a leading technology media prope...</td>\n",
       "      <td>https://techcrunch.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Next Web</th>\n",
       "      <td>the-next-web</td>\n",
       "      <td>The Next Web is one of the world’s largest onl...</td>\n",
       "      <td>http://thenextweb.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Verge</th>\n",
       "      <td>the-verge</td>\n",
       "      <td>The Verge covers the intersection of technolog...</td>\n",
       "      <td>http://www.theverge.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wired</th>\n",
       "      <td>wired</td>\n",
       "      <td>Wired is a monthly American magazine, publishe...</td>\n",
       "      <td>https://www.wired.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">sports</th>\n",
       "      <th>BBC Sport</th>\n",
       "      <td>bbc-sport</td>\n",
       "      <td>The home of BBC Sport online. Includes live sp...</td>\n",
       "      <td>http://www.bbc.co.uk/sport</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESPN</th>\n",
       "      <td>espn</td>\n",
       "      <td>ESPN has up-to-the-minute sports news coverage...</td>\n",
       "      <td>https://www.espn.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fox Sports</th>\n",
       "      <td>fox-sports</td>\n",
       "      <td>Find live scores, player and team news, videos...</td>\n",
       "      <td>http://www.foxsports.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TalkSport</th>\n",
       "      <td>talksport</td>\n",
       "      <td>Tune in to the world's biggest sports radio st...</td>\n",
       "      <td>http://talksport.com</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Sport Bible</th>\n",
       "      <td>the-sport-bible</td>\n",
       "      <td>TheSPORTbible is one of the largest communitie...</td>\n",
       "      <td>https://www.thesportbible.com</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">entertainment</th>\n",
       "      <th>Buzzfeed</th>\n",
       "      <td>buzzfeed</td>\n",
       "      <td>BuzzFeed is a cross-platform, global network f...</td>\n",
       "      <td>https://www.buzzfeed.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entertainment Weekly</th>\n",
       "      <td>entertainment-weekly</td>\n",
       "      <td>Online version of the print magazine includes ...</td>\n",
       "      <td>http://www.ew.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IGN</th>\n",
       "      <td>ign</td>\n",
       "      <td>IGN is your site for Xbox One, PS4, PC, Wii-U,...</td>\n",
       "      <td>http://www.ign.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Lad Bible</th>\n",
       "      <td>the-lad-bible</td>\n",
       "      <td>The LAD Bible is one of the largest community ...</td>\n",
       "      <td>https://www.theladbible.com</td>\n",
       "      <td>en</td>\n",
       "      <td>gb</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <th>Medical News Today</th>\n",
       "      <td>medical-news-today</td>\n",
       "      <td>Medical news and health news headlines posted ...</td>\n",
       "      <td>http://www.medicalnewstoday.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">science</th>\n",
       "      <th>National Geographic</th>\n",
       "      <td>national-geographic</td>\n",
       "      <td>Reporting our world daily: original nature and...</td>\n",
       "      <td>http://news.nationalgeographic.com</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Scientist</th>\n",
       "      <td>new-scientist</td>\n",
       "      <td>Breaking science and technology news from arou...</td>\n",
       "      <td>https://www.newscientist.com/section/news</td>\n",
       "      <td>en</td>\n",
       "      <td>us</td>\n",
       "      <td>2024-06-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            id  \\\n",
       "Category      Source Name                                        \n",
       "general       ABC News                                abc-news   \n",
       "              Al Jazeera English            al-jazeera-english   \n",
       "              BBC News                                bbc-news   \n",
       "              CBS News                                cbs-news   \n",
       "              CNN                                          cnn   \n",
       "              Google News                          google-news   \n",
       "              Google News (India)               google-news-in   \n",
       "              New York Magazine              new-york-magazine   \n",
       "              Politico                                politico   \n",
       "              Reddit /r/all                       reddit-r-all   \n",
       "              Reuters                                  reuters   \n",
       "              The Hindu                              the-hindu   \n",
       "              The Times of India            the-times-of-india   \n",
       "              The Washington Post          the-washington-post   \n",
       "              The Washington Times        the-washington-times   \n",
       "              Time                                        time   \n",
       "              Vice News                              vice-news   \n",
       "business      Bloomberg                              bloomberg   \n",
       "              Business Insider                business-insider   \n",
       "              Business Insider (UK)        business-insider-uk   \n",
       "              Financial Post                    financial-post   \n",
       "              Fortune                                  fortune   \n",
       "              InfoMoney                             info-money   \n",
       "              The Wall Street Journal  the-wall-street-journal   \n",
       "technology    Crypto Coins News              crypto-coins-news   \n",
       "              Hacker News                          hacker-news   \n",
       "              Recode                                    recode   \n",
       "              TechCrunch                            techcrunch   \n",
       "              The Next Web                        the-next-web   \n",
       "              The Verge                              the-verge   \n",
       "              Wired                                      wired   \n",
       "sports        BBC Sport                              bbc-sport   \n",
       "              ESPN                                        espn   \n",
       "              Fox Sports                            fox-sports   \n",
       "              TalkSport                              talksport   \n",
       "              The Sport Bible                  the-sport-bible   \n",
       "entertainment Buzzfeed                                buzzfeed   \n",
       "              Entertainment Weekly        entertainment-weekly   \n",
       "              IGN                                          ign   \n",
       "              The Lad Bible                      the-lad-bible   \n",
       "health        Medical News Today            medical-news-today   \n",
       "science       National Geographic          national-geographic   \n",
       "              New Scientist                      new-scientist   \n",
       "\n",
       "                                                                             description  \\\n",
       "Category      Source Name                                                                  \n",
       "general       ABC News                 Your trusted source for breaking news, analysi...   \n",
       "              Al Jazeera English       News, analysis from the Middle East and worldw...   \n",
       "              BBC News                 Use BBC News for up-to-the-minute news, breaki...   \n",
       "              CBS News                 CBS News: dedicated to providing the best in j...   \n",
       "              CNN                      View the latest news and breaking news today f...   \n",
       "              Google News              Comprehensive, up-to-date news coverage, aggre...   \n",
       "              Google News (India)      Comprehensive, up-to-date India news coverage,...   \n",
       "              New York Magazine        NYMAG and New York magazine cover the new, the...   \n",
       "              Politico                 Political news about Congress, the White House...   \n",
       "              Reddit /r/all            Reddit is an entertainment, social news networ...   \n",
       "              Reuters                  Reuters.com brings you the latest news from ar...   \n",
       "              The Hindu                The Hindu. latest news, analysis, comment, in-...   \n",
       "              The Times of India       Times of India brings the Latest News and Top ...   \n",
       "              The Washington Post      Breaking news and analysis on politics, busine...   \n",
       "              The Washington Times     The Washington Times delivers breaking news an...   \n",
       "              Time                     Breaking news and analysis from TIME.com. Poli...   \n",
       "              Vice News                Vice News is Vice Media, Inc.'s current affair...   \n",
       "business      Bloomberg                Bloomberg delivers business and markets news, ...   \n",
       "              Business Insider         Business Insider is a fast-growing business si...   \n",
       "              Business Insider (UK)    Business Insider is a fast-growing business si...   \n",
       "              Financial Post           Find the latest happenings in the Canadian Fin...   \n",
       "              Fortune                       Fortune 500 Daily and Breaking Business News   \n",
       "              InfoMoney                No InfoMoney você encontra tudo o que precisa ...   \n",
       "              The Wall Street Journal  WSJ online coverage of breaking news and curre...   \n",
       "technology    Crypto Coins News        Providing breaking cryptocurrency news - focus...   \n",
       "              Hacker News              Hacker News is a social news website focusing ...   \n",
       "              Recode                   Get the latest independent tech news, reviews ...   \n",
       "              TechCrunch               TechCrunch is a leading technology media prope...   \n",
       "              The Next Web             The Next Web is one of the world’s largest onl...   \n",
       "              The Verge                The Verge covers the intersection of technolog...   \n",
       "              Wired                    Wired is a monthly American magazine, publishe...   \n",
       "sports        BBC Sport                The home of BBC Sport online. Includes live sp...   \n",
       "              ESPN                     ESPN has up-to-the-minute sports news coverage...   \n",
       "              Fox Sports               Find live scores, player and team news, videos...   \n",
       "              TalkSport                Tune in to the world's biggest sports radio st...   \n",
       "              The Sport Bible          TheSPORTbible is one of the largest communitie...   \n",
       "entertainment Buzzfeed                 BuzzFeed is a cross-platform, global network f...   \n",
       "              Entertainment Weekly     Online version of the print magazine includes ...   \n",
       "              IGN                      IGN is your site for Xbox One, PS4, PC, Wii-U,...   \n",
       "              The Lad Bible            The LAD Bible is one of the largest community ...   \n",
       "health        Medical News Today       Medical news and health news headlines posted ...   \n",
       "science       National Geographic      Reporting our world daily: original nature and...   \n",
       "              New Scientist            Breaking science and technology news from arou...   \n",
       "\n",
       "                                                                             url  \\\n",
       "Category      Source Name                                                          \n",
       "general       ABC News                                    https://abcnews.go.com   \n",
       "              Al Jazeera English                       https://www.aljazeera.com   \n",
       "              BBC News                                https://www.bbc.co.uk/news   \n",
       "              CBS News                                    http://www.cbsnews.com   \n",
       "              CNN                                              http://us.cnn.com   \n",
       "              Google News                                https://news.google.com   \n",
       "              Google News (India)                        https://news.google.com   \n",
       "              New York Magazine                                 http://nymag.com   \n",
       "              Politico                                  https://www.politico.com   \n",
       "              Reddit /r/all                         https://www.reddit.com/r/all   \n",
       "              Reuters                                    https://www.reuters.com   \n",
       "              The Hindu                                  http://www.thehindu.com   \n",
       "              The Times of India              http://timesofindia.indiatimes.com   \n",
       "              The Washington Post                 https://www.washingtonpost.com   \n",
       "              The Washington Times              https://www.washingtontimes.com/   \n",
       "              Time                                               http://time.com   \n",
       "              Vice News                                    https://news.vice.com   \n",
       "business      Bloomberg                                 http://www.bloomberg.com   \n",
       "              Business Insider                    http://www.businessinsider.com   \n",
       "              Business Insider (UK)                http://uk.businessinsider.com   \n",
       "              Financial Post                           https://financialpost.com   \n",
       "              Fortune                                         http://fortune.com   \n",
       "              InfoMoney                             https://www.infomoney.com.br   \n",
       "              The Wall Street Journal                         http://www.wsj.com   \n",
       "technology    Crypto Coins News                              https://www.ccn.com   \n",
       "              Hacker News                           https://news.ycombinator.com   \n",
       "              Recode                                       http://www.recode.net   \n",
       "              TechCrunch                                  https://techcrunch.com   \n",
       "              The Next Web                                 http://thenextweb.com   \n",
       "              The Verge                                  http://www.theverge.com   \n",
       "              Wired                                        https://www.wired.com   \n",
       "sports        BBC Sport                               http://www.bbc.co.uk/sport   \n",
       "              ESPN                                          https://www.espn.com   \n",
       "              Fox Sports                                http://www.foxsports.com   \n",
       "              TalkSport                                     http://talksport.com   \n",
       "              The Sport Bible                      https://www.thesportbible.com   \n",
       "entertainment Buzzfeed                                  https://www.buzzfeed.com   \n",
       "              Entertainment Weekly                             http://www.ew.com   \n",
       "              IGN                                             http://www.ign.com   \n",
       "              The Lad Bible                          https://www.theladbible.com   \n",
       "health        Medical News Today                 http://www.medicalnewstoday.com   \n",
       "science       National Geographic             http://news.nationalgeographic.com   \n",
       "              New Scientist            https://www.newscientist.com/section/news   \n",
       "\n",
       "                                      language country yesterday_date  \n",
       "Category      Source Name                                              \n",
       "general       ABC News                      en      us     2024-06-07  \n",
       "              Al Jazeera English            en      us     2024-06-07  \n",
       "              BBC News                      en      gb     2024-06-07  \n",
       "              CBS News                      en      us     2024-06-07  \n",
       "              CNN                           en      us     2024-06-07  \n",
       "              Google News                   en      us     2024-06-07  \n",
       "              Google News (India)           en      in     2024-06-07  \n",
       "              New York Magazine             en      us     2024-06-07  \n",
       "              Politico                      en      us     2024-06-07  \n",
       "              Reddit /r/all                 en      us     2024-06-07  \n",
       "              Reuters                       en      us     2024-06-07  \n",
       "              The Hindu                     en      in     2024-06-07  \n",
       "              The Times of India            en      in     2024-06-07  \n",
       "              The Washington Post           en      us     2024-06-07  \n",
       "              The Washington Times          en      us     2024-06-07  \n",
       "              Time                          en      us     2024-06-07  \n",
       "              Vice News                     en      us     2024-06-07  \n",
       "business      Bloomberg                     en      us     2024-06-07  \n",
       "              Business Insider              en      us     2024-06-07  \n",
       "              Business Insider (UK)         en      gb     2024-06-07  \n",
       "              Financial Post                en      ca     2024-06-07  \n",
       "              Fortune                       en      us     2024-06-07  \n",
       "              InfoMoney                     pt      br     2024-06-07  \n",
       "              The Wall Street Journal       en      us     2024-06-07  \n",
       "technology    Crypto Coins News             en      us     2024-06-07  \n",
       "              Hacker News                   en      us     2024-06-07  \n",
       "              Recode                        en      us     2024-06-07  \n",
       "              TechCrunch                    en      us     2024-06-07  \n",
       "              The Next Web                  en      us     2024-06-07  \n",
       "              The Verge                     en      us     2024-06-07  \n",
       "              Wired                         en      us     2024-06-07  \n",
       "sports        BBC Sport                     en      gb     2024-06-07  \n",
       "              ESPN                          en      us     2024-06-07  \n",
       "              Fox Sports                    en      us     2024-06-07  \n",
       "              TalkSport                     en      gb     2024-06-07  \n",
       "              The Sport Bible               en      gb     2024-06-07  \n",
       "entertainment Buzzfeed                      en      us     2024-06-07  \n",
       "              Entertainment Weekly          en      us     2024-06-07  \n",
       "              IGN                           en      us     2024-06-07  \n",
       "              The Lad Bible                 en      gb     2024-06-07  \n",
       "health        Medical News Today            en      us     2024-06-07  \n",
       "science       National Geographic           en      us     2024-06-07  \n",
       "              New Scientist                 en      us     2024-06-07  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 0 has been saved to output_files\\output_0.txt\n",
      "The text for index 1 has been saved to output_files\\output_1.txt\n",
      "The text for index 2 has been saved to output_files\\output_2.txt\n",
      "The text for index 3 has been saved to output_files\\output_3.txt\n",
      "The text for index 4 has been saved to output_files\\output_4.txt\n",
      "The text for index 5 has been saved to output_files\\output_5.txt\n",
      "The text for index 6 has been saved to output_files\\output_6.txt\n",
      "The text for index 7 has been saved to output_files\\output_7.txt\n",
      "The text for index 8 has been saved to output_files\\output_8.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 9\n",
      "The text for index 10 has been saved to output_files\\output_10.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 11\n",
      "The text for index 12 has been saved to output_files\\output_12.txt\n",
      "The text for index 13 has been saved to output_files\\output_13.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 14\n",
      "The text for index 15 has been saved to output_files\\output_15.txt\n",
      "The text for index 16 has been saved to output_files\\output_16.txt\n",
      "The text for index 17 has been saved to output_files\\output_17.txt\n",
      "The text for index 18 has been saved to output_files\\output_18.txt\n",
      "The text for index 19 has been saved to output_files\\output_19.txt\n",
      "The text for index 20 has been saved to output_files\\output_20.txt\n",
      "The text for index 21 has been saved to output_files\\output_21.txt\n",
      "The text for index 22 has been saved to output_files\\output_22.txt\n",
      "The text for index 23 has been saved to output_files\\output_23.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 24\n",
      "The text for index 25 has been saved to output_files\\output_25.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 26\n",
      "The text for index 27 has been saved to output_files\\output_27.txt\n",
      "The text for index 28 has been saved to output_files\\output_28.txt\n",
      "The text for index 29 has been saved to output_files\\output_29.txt\n",
      "The text for index 30 has been saved to output_files\\output_30.txt\n",
      "The text for index 31 has been saved to output_files\\output_31.txt\n",
      "The text for index 32 has been saved to output_files\\output_32.txt\n",
      "The text for index 33 has been saved to output_files\\output_33.txt\n",
      "The text for index 34 has been saved to output_files\\output_34.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 35\n",
      "The text for index 36 has been saved to output_files\\output_36.txt\n",
      "The text for index 37 has been saved to output_files\\output_37.txt\n",
      "The text for index 38 has been saved to output_files\\output_38.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 39\n",
      "The text for index 40 has been saved to output_files\\output_40.txt\n",
      "The text for index 41 has been saved to output_files\\output_41.txt\n",
      "The text for index 42 has been saved to output_files\\output_42.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_categories is already defined and contains the necessary data\n",
    "\n",
    "# Define the directory where files will be saved\n",
    "output_dir = 'output_files'\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for n in range(43):\n",
    "    try:\n",
    "        df_trial = df_categories.iloc[[n], :].copy()\n",
    "        df_trial['data'] = df_trial.apply(\n",
    "            lambda row: json_to_df(fetch_json(row['id'], row['yesterday_date'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Apply the function to clean up each DataFrame in the 'data' column\n",
    "        df_trial['data'] = df_trial['data'].apply(remove_empty_content)\n",
    "        \n",
    "        # Remove rows where 'data' column has empty DataFrames\n",
    "        df_trial1 = df_trial[df_trial['data'].apply(lambda x: not x.empty)].copy()\n",
    "        \n",
    "        # Check if df_trial1 is not empty and the 'content' column has sufficient elements\n",
    "        if not df_trial1.empty and 'content' in df_trial1['data'].iloc[0] and len(df_trial1['data'].iloc[0]['content']) > 0:\n",
    "            \n",
    "            #make a csv of this df_trial1['data'][0]\n",
    "            df_trial1['data'][0].to_csv(f'output_{n}.csv')\n",
    "\n",
    "            text = df_trial1['data'].iloc[0]['content'][0]\n",
    "            \n",
    "            # Replace each period with a period followed by a newline character\n",
    "            formatted_text = text.replace('.', '.\\n')\n",
    "            \n",
    "            # Extract the URL\n",
    "            url = df_trial1['data'].iloc[0]['url'][0]\n",
    "            \n",
    "            # Append the URL to the formatted text\n",
    "            formatted_text += f\"\\n\\nURL: {url}\"\n",
    "            \n",
    "            # Define the filename\n",
    "            filename = os.path.join(output_dir, f'output_{n}.txt')\n",
    "            \n",
    "            # Open the file in write mode and save the formatted text\n",
    "            with open(filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(formatted_text)\n",
    "            \n",
    "            print(f\"The text for index {n} has been saved to {filename}\")\n",
    "        else:\n",
    "            print(f\"No sufficient content available for index {n}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for index {n}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 0 has been saved to output_files\\output_0.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 1 has been saved to output_files\\output_1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 2 has been saved to output_files\\output_2.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 3 has been saved to output_files\\output_3.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 4 has been saved to output_files\\output_4.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 5 has been saved to output_files\\output_5.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 6 has been saved to output_files\\output_6.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 7 has been saved to output_files\\output_7.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 8 has been saved to output_files\\output_8.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 10 has been saved to output_files\\output_10.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 12 has been saved to output_files\\output_12.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 13 has been saved to output_files\\output_13.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 15 has been saved to output_files\\output_15.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 16 has been saved to output_files\\output_16.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 17 has been saved to output_files\\output_17.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 18 has been saved to output_files\\output_18.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 19 has been saved to output_files\\output_19.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 20 has been saved to output_files\\output_20.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 21 has been saved to output_files\\output_21.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 22 has been saved to output_files\\output_22.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 23 has been saved to output_files\\output_23.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 25 has been saved to output_files\\output_25.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 27 has been saved to output_files\\output_27.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 28 has been saved to output_files\\output_28.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 29 has been saved to output_files\\output_29.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 30 has been saved to output_files\\output_30.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 31 has been saved to output_files\\output_31.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 32 has been saved to output_files\\output_32.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 33 has been saved to output_files\\output_33.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 34 has been saved to output_files\\output_34.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 36 has been saved to output_files\\output_36.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 37 has been saved to output_files\\output_37.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 38 has been saved to output_files\\output_38.txt\n",
      "ValueError: No articles found for the given date.\n",
      "No sufficient content available for index 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 40 has been saved to output_files\\output_40.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text for index 41 has been saved to output_files\\output_41.txt\n",
      "The text for index 42 has been saved to output_files\\output_42.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_6816\\2301266507.py:33: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df_categories is already defined and contains the necessary data\n",
    "\n",
    "# Define the directories where files will be saved\n",
    "output_dir = 'output_files'\n",
    "csv_output_dir = 'csv_output_files'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(csv_output_dir, exist_ok=True)\n",
    "\n",
    "for n in range(43):\n",
    "    try:\n",
    "        df_trial = df_categories.iloc[[n], :].copy()\n",
    "        df_trial['data'] = df_trial.apply(\n",
    "            lambda row: json_to_df(fetch_json(row['id'], row['yesterday_date'])),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # Apply the function to clean up each DataFrame in the 'data' column\n",
    "        df_trial['data'] = df_trial['data'].apply(remove_empty_content)\n",
    "        \n",
    "        # Remove rows where 'data' column has empty DataFrames\n",
    "        df_trial1 = df_trial[df_trial['data'].apply(lambda x: not x.empty)].copy()\n",
    "        \n",
    "        # Check if df_trial1 is not empty and the 'content' column has sufficient elements\n",
    "        if not df_trial1.empty and 'content' in df_trial1['data'].iloc[0] and len(df_trial1['data'].iloc[0]['content']) > 0:\n",
    "            \n",
    "            # Save a CSV of this df_trial1['data'][0]\n",
    "            csv_filename = f'output_{n}.csv'\n",
    "            df_trial1['data'][0].to_csv(os.path.join(csv_output_dir, csv_filename))\n",
    "\n",
    "            text = df_trial1['data'].iloc[0]['content'][0]\n",
    "            \n",
    "            # Replace each period with a period followed by a newline character\n",
    "            formatted_text = text.replace('.', '.\\n')\n",
    "            \n",
    "            # Extract the URL\n",
    "            url = df_trial1['data'].iloc[0]['url'][0]\n",
    "            \n",
    "            # Append the URL to the formatted text\n",
    "            formatted_text += f\"\\n\\nURL: {url}\"\n",
    "            \n",
    "            # Define the filename\n",
    "            text_filename = os.path.join(output_dir, f'output_{n}.txt')\n",
    "            \n",
    "            # Open the file in write mode and save the formatted text\n",
    "            with open(text_filename, 'w', encoding='utf-8') as file:\n",
    "                file.write(formatted_text)\n",
    "            \n",
    "            print(f\"The text for index {n} has been saved to {text_filename}\")\n",
    "        else:\n",
    "            print(f\"No sufficient content available for index {n}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for index {n}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
