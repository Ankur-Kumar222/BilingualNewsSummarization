{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1fc4122b324d618484d4d0d148e9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d7235e1b5a45c48de4d1aae04f0812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.39 seconds, 5.10 sentences/sec\n",
      "Precision: 0.9669605493545532\n",
      "Recall: 0.9702423214912415\n",
      "F1 Score: 0.9685958027839661\n"
     ]
    }
   ],
   "source": [
    "from bert_score import score\n",
    "\n",
    "# Example data\n",
    "reference_summaries = [\n",
    "    \"The cat sat on the mat.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "\n",
    "generated_summaries = [\n",
    "    \"A cat was sitting on a mat.\",\n",
    "    \"A fast brown fox jumped over a lazy dog.\"\n",
    "]\n",
    "\n",
    "# Calculate BERTScore\n",
    "P, R, F1 = score(generated_summaries, reference_summaries, lang=\"en\", verbose=True)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Precision: {P.mean().item()}\")\n",
    "print(f\"Recall: {R.mean().item()}\")\n",
    "print(f\"F1 Score: {F1.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METEOR score: 0.6463768115942029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Function to calculate METEOR score\n",
    "def calculate_meteor(candidate, reference):\n",
    "    candidate_tokens = nltk.word_tokenize(candidate)\n",
    "    reference_tokens = [nltk.word_tokenize(reference)]\n",
    "    \n",
    "    score = meteor_score(reference_tokens, candidate_tokens)\n",
    "    return score\n",
    "\n",
    "# Example usage\n",
    "candidate_translation = \"the cat is on the mat\"\n",
    "reference_translation = \"there is a cat on the mat\"\n",
    "\n",
    "meteor = calculate_meteor(candidate_translation, reference_translation)\n",
    "print(\"METEOR score:\", meteor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv('OPEN_AI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 2020 World Series was played at Globe Life Field in Arlington, Texas.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4016ff64750c4ea4962b4792cc6fab37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faf8e36666c4a5eb43106b9695c3096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.29 seconds, 6.83 sentences/sec\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Mean METEOR score: 0.7241682242990655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from bert_score import score\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Define your OpenAI API key\n",
    "client = OpenAI(api_key= key)\n",
    "# Generate summaries and translations\n",
    "def generate_summary(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following text: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def translate_summary(summary):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following to Hindi: {summary}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example data\n",
    "texts = [\"The cat sat on the mat.\", \"The quick brown fox jumps over the lazy dog.\"]\n",
    "reference_summaries = [\"The cat sat on the mat.\", \"The quick brown fox jumps over the lazy dog.\"]\n",
    "reference_translations = [\"बिल्ली चटाई पर बैठी थी।\", \"तेज़ भूरे रंग की लोमड़ी आलसी कुत्ते के ऊपर कूदती है।\"]\n",
    "\n",
    "# Generate summaries and translations using ChatGPT\n",
    "generated_summaries = [generate_summary(text) for text in texts]\n",
    "generated_translations = [translate_summary(summary) for summary in generated_summaries]\n",
    "\n",
    "# Evaluate BERTScore for summarization\n",
    "P, R, F1 = score(generated_summaries, reference_summaries, lang=\"en\", verbose=True)\n",
    "print(f\"Precision: {P.mean().item()}\")\n",
    "print(f\"Recall: {R.mean().item()}\")\n",
    "print(f\"F1 Score: {F1.mean().item()}\")\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Evaluate METEOR score for translation\n",
    "def calculate_meteor(candidate, reference):\n",
    "    candidate_tokens = nltk.word_tokenize(candidate)\n",
    "    reference_tokens = [nltk.word_tokenize(reference)]\n",
    "    \n",
    "    score = meteor_score(reference_tokens, candidate_tokens)\n",
    "    return score\n",
    "\n",
    "meteor_scores = [calculate_meteor(candidate, reference) for candidate, reference in zip(generated_translations, reference_translations)]\n",
    "mean_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(\"Mean METEOR score:\", mean_meteor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['बिल्ली चटाई पर बैठी थी।', 'तेज काला लोमड़ी आलसी कुत्ते पर कूदती है।']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The cat sat on the mat.', 'The quick brown fox jumps over the lazy dog.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "with open('news.json', 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"When I finally saw my hand, that\\'s when I started freaking out.\" An Oklahoma teen and her family are speaking out after the 19-year-old was attacked by a shark last month in Galveston, Texas. Damiana Humphrey, 19, told \"Good Morning America\" she was wading in the water about waist-deep when a 4 to 5-foot shark latched onto her hand. She says she started punching the shark until she was freed. \"When I finally saw my hand, that\\'s when I started freaking out,\" she told \"GMA.\" Humphrey\\'s father, Troy, also spoke to \"GMA.\" \"I noticed that she had her hand held up and that it was bleeding down her arm,\" he said. The teen was rushed to the hospital, where she had surgery on her hand. \"I severed four tendons. And then I basically had a big hole on the top of my hand that they had to sew together,\" she said. \"That shark was looking for food for prey, and in murky water, all they see is a flash of movement, and so that shark came in to investigate, and this was just a case of mistaken identity,\" Dr. Kesley Banks, a research scientist at the Harte Research Institute, told \"GMA.\" With summer approaching, several shark attacks have recently made headlines across the U.S. Three swimmers, including two teens, were attacked by sharks in two separate incidents while they were at beaches in Walton County, Florida, on Friday. In Hawaii, a 25-year-old woman was taken to a hospital following a shark bite incident off Oahu’s North Shore on Friday at around 2 p.m. local time, the Honolulu Emergency Services reported. \"EMS responded to the Haleiwa Small Boat Harbor where the patient had been brought ashore. EMS treated her for multiple serious lacerations before transporting her to an emergency room,\" the agency stated. A 46-year-old man was left with \"significant\" injuries after being bit by a shark in Southern California earlier this month, officials said. While experts and officials advised beachgoers to take precautions, including avoiding swimming at dusk or dawn, Damiana Humphrey said the shark attack hasn\\'t stopped her from getting back in the water. 24/7 coverage of breaking news and live events'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data'][0][50]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =[]\n",
    "for i in range(10):\n",
    "    texts.append(df['data'][0][i]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, MBartForConditionalGeneration, MBart50Tokenizer\n",
    "\n",
    "def load_models():\n",
    "    bart_model_name = \"facebook/bart-large-cnn\"\n",
    "    bart_tokenizer = BartTokenizer.from_pretrained(bart_model_name)\n",
    "    bart_model = BartForConditionalGeneration.from_pretrained(bart_model_name)\n",
    "    \n",
    "    mbart_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "    mbart_tokenizer = MBart50Tokenizer.from_pretrained(mbart_model_name)\n",
    "    mbart_model = MBartForConditionalGeneration.from_pretrained(mbart_model_name)\n",
    "    mbart_tokenizer.src_lang = \"en_XX\"\n",
    "    return bart_model, bart_tokenizer, mbart_model, mbart_tokenizer\n",
    "\n",
    "bart_model, bart_tokenizer, mbart_model, mbart_tokenizer = load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(text):\n",
    "    inputs = bart_tokenizer(text, max_length=1024, return_tensors='pt', truncation=True)\n",
    "    summary_ids = bart_model.generate(inputs['input_ids'], num_beams=4, max_length=150, early_stopping=True)\n",
    "    summary = bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_hindi(text):\n",
    "    inputs = mbart_tokenizer(text, return_tensors='pt', truncation=True)\n",
    "    translated_ids = mbart_model.generate(inputs['input_ids'], num_beams=4, max_length=150, early_stopping=True, forced_bos_token_id=mbart_tokenizer.lang_code_to_id[\"hi_IN\"])\n",
    "    translation = mbart_tokenizer.decode(translated_ids[0], skip_special_tokens=True)\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "reference_summaries = []\n",
    "counter = 0\n",
    "for i in texts:\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "    reference_summaries.append(summarize_article(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "reference_translations = []\n",
    "for summary in reference_summaries:\n",
    "    counter+=1\n",
    "    print(counter)\n",
    "    reference_translations.append(translate_to_hindi(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ankur\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9ae6f130594fe59dfcf9e41cc5c568",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2f1cdb58344739843ca8afb6ea8eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 15.43 seconds, 0.65 sentences/sec\n",
      "Precision: 0.8664615750312805\n",
      "Recall: 0.8932830095291138\n",
      "F1 Score: 0.8795720934867859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ankur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean METEOR score: 0.22887180504528093\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from bert_score import score\n",
    "import nltk\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "# Define your OpenAI API key\n",
    "client = OpenAI(api_key= key)\n",
    "# Generate summaries and translations\n",
    "def generate_summary(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Summarize the following text: {text}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def translate_summary(summary):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Translate the following to Hindi: {summary}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Generate summaries and translations using ChatGPT\n",
    "generated_summaries = [generate_summary(text) for text in texts]\n",
    "generated_translations = [translate_summary(summary) for summary in generated_summaries]\n",
    "\n",
    "# Evaluate BERTScore for summarization\n",
    "P, R, F1 = score(generated_summaries, reference_summaries, lang=\"en\", verbose=True)\n",
    "print(f\"Precision: {P.mean().item()}\")\n",
    "print(f\"Recall: {R.mean().item()}\")\n",
    "print(f\"F1 Score: {F1.mean().item()}\")\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Evaluate METEOR score for translation\n",
    "def calculate_meteor(candidate, reference):\n",
    "    candidate_tokens = nltk.word_tokenize(candidate)\n",
    "    reference_tokens = [nltk.word_tokenize(reference)]\n",
    "    \n",
    "    score = meteor_score(reference_tokens, candidate_tokens)\n",
    "    return score\n",
    "\n",
    "meteor_scores = [calculate_meteor(candidate, reference) for candidate, reference in zip(generated_translations, reference_translations)]\n",
    "mean_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "\n",
    "print(\"Mean METEOR score:\", mean_meteor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
